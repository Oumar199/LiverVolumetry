{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "C02gJb1Te6__"
      },
      "outputs": [],
      "source": [
        "# @title üíª Verify GPU Configuration (Activate GPU for faster execution)\n",
        "\n",
        "from google.colab import output\n",
        "import torch\n",
        "\n",
        "if not torch.cuda.is_available():\n",
        "    from IPython.display import display, Markdown\n",
        "    display(Markdown(\"## ‚ùå **ERROR : GPU is not detected**\"))\n",
        "    display(Markdown(\"Go to **Runtime > Change runtime type** and selection **T4 GPU**.\"))\n",
        "\n",
        "    output.eval_js('alert(\"Missing GPU !\")')\n",
        "    raise SystemError(\"The GPU must be activated to continue.\")\n",
        "else:\n",
        "    print(\"‚úÖ GPU d√©tect√© :\", torch.cuda.get_device_name(0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "7jku0s5Se4VJ"
      },
      "outputs": [],
      "source": [
        "# @title üõ†Ô∏è 1. Setup Environment (restart the session after installation)\n",
        "!git clone https://github.com/Oumar199/LiverVolumetry.git\n",
        "!pip install -e LiverVolumetry/liver-volumetry -qqq\n",
        "\n",
        "\n",
        "print(\"\\n‚úÖ Environment ready. Runtime needs to restarted !\")\n",
        "\n",
        "import os\n",
        "os._exit(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "EvAv1A_QfMrN"
      },
      "outputs": [],
      "source": [
        "# @title üìÇ 2. Data Preparation\n",
        "from google.colab import files\n",
        "from IPython.display import Image, display\n",
        "import os\n",
        "\n",
        "print(\"Choose an option:\")\n",
        "print(\"1. Use default sample image\")\n",
        "print(\"2. Upload your own image\")\n",
        "\n",
        "choice = input(\"Enter 1 or 2: \")\n",
        "\n",
        "IMAGE_PATH = 'images/output_liver_segmentation.jpg'\n",
        "\n",
        "if choice == '2':\n",
        "    uploaded = files.upload()\n",
        "    if uploaded:\n",
        "        filename = list(uploaded.keys())[0]\n",
        "        IMAGE_PATH = os.path.join('images', filename)\n",
        "        print(f\"‚úÖ Uploaded: {filename}\")\n",
        "else:\n",
        "    if not os.path.exists(IMAGE_PATH):\n",
        "        !mkdir -p images\n",
        "        !wget -O {IMAGE_PATH} https://github.com/Oumar199/LiverVolumetry/blob/main/images/output_liver_segmentation.jpg?raw=true\n",
        "    print(\"‚úÖ Using default sample.\")\n",
        "\n",
        "display(Image(IMAGE_PATH, width=400))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sfivk0rIhNM-",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title üî¨ 3.2 Segmentation & Volumetry\n",
        "%cd LiverVolumetry\n",
        "\n",
        "from liver_volumetry.interpretation.analysis import get_models, load_image, segment_image, identify_volumes\n",
        "from liver_volumetry.utils import liver_tumor_pipeline_py as ltp\n",
        "\n",
        "# 1. Load models and image\n",
        "print(\"Loading models... (this may take a moment)\")\n",
        "liver_model, tumor_model = get_models()\n",
        "img = load_image(IMAGE_PATH)\n",
        "\n",
        "# 2. Run Segmentation\n",
        "print(\"Running segmentation pipeline...\")\n",
        "liver_mask, tumor_mask = segment_image(img, (liver_model, tumor_model))\n",
        "\n",
        "# 3. Calculate Volumetry\n",
        "# Returns overlay and dictionary with volumes (e.g., {'liver': 1500, 'tumor': 50})\n",
        "overlay, volumes = identify_volumes(img, (liver_mask, tumor_mask))\n",
        "\n",
        "print(f\"\\nüìä Calculated Volumes: {volumes}\")\n",
        "\n",
        "# 4. Plot Results\n",
        "# Set get_image=False to display directly in the notebook\n",
        "ltp.plot_results(\n",
        "    img_array=img,\n",
        "    liver_mask=liver_mask,\n",
        "    tumor_mask=tumor_mask,\n",
        "    get_image=False\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "LD_V097ZhbOc"
      },
      "outputs": [],
      "source": [
        "# @title üöÄ Run Local AI Analysis (Medgemma-1.5-4b)\n",
        "from liver_volumetry.interpretation.analysis import analysis_image\n",
        "from liver_volumetry.utils import liver_tumor_pipeline_py as ltp\n",
        "from IPython.display import display, Markdown\n",
        "\n",
        "try:\n",
        "    print(\"‚è≥ Loading Medgemma model (this requires significant VRAM)...\")\n",
        "    # 1. Load the quantized Medgemma model and processor\n",
        "    llm_model, processor = ltp.load_medgemma_4bit()\n",
        "\n",
        "    # 2. Run full pipeline (Segmentation + Volumetry + AI Interpretation)\n",
        "    # Returns: Medical analysis text, calculated volumes, and base64 plot string\n",
        "    # We pass 'img' and 'models' (liver_model, tumor_model) from the previous cell\n",
        "    models = (liver_model, tumor_model)\n",
        "    result = analysis_image(img, models, llm_model, processor, get_image=True)\n",
        "\n",
        "    # 3. Extract and display the medical interpretation\n",
        "    # Splitting the result to isolate the generated clinical text\n",
        "    analysis = result[0].split(\"\\nmodel\\n\", 1)[1]\n",
        "\n",
        "    print(\"\\n\" + \"=\"*30)\n",
        "    print(\"üìã CLINICAL INSIGHT\")\n",
        "    print(\"=\"*30)\n",
        "\n",
        "    display(Markdown(analysis))\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Local analysis failed: {e}\")\n",
        "    print(\"\\nüí° Suggestion: If you lack local GPU resources, please use the 'RunPod Remote Analysis' section below.\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}